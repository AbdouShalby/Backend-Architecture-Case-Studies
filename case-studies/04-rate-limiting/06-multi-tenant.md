# 6. Multi-Tenant Quotas

> "A rate limiter without tenant isolation is just a global traffic light. Real multi-tenant quota management means: different limits per plan, burst allowances that don't steal from each other, and billing-grade accuracy for quota overages."

---

## ğŸ“Š Tenant Plans

### Plan Tiers

| Feature | Free | Pro ($49/mo) | Business ($199/mo) | Enterprise (Custom) |
|---------|------|-------------|-------------------|-------------------|
| Requests/min | 100 | 1,000 | 10,000 | 100,000+ |
| Requests/day | 10,000 | 100,000 | 1,000,000 | Unlimited |
| Burst allowance | None | 1.5Ã— for 10s | 2Ã— for 30s | 3Ã— for 60s |
| Rate limit algorithm | Fixed window | Sliding window | Token bucket | Token bucket |
| Endpoints | All same limit | All same limit | Per-endpoint limits | Custom per-endpoint |
| Concurrent connections | 5 | 25 | 100 | Custom |
| Support | Community | Email (24h) | Priority (4h) | Dedicated (1h) |

### Why Different Algorithms Per Plan?

```
Free tier â†’ Fixed window:
  Cheapest to compute (1 Redis op per check).
  Boundary spike (2Ã—) is acceptable â€” free users don't need precision.
  
Pro tier â†’ Sliding window counter:
  More accurate. Users paying $49/mo deserve fair counting.
  Still cheap (2 Redis ops per check).

Business/Enterprise â†’ Token bucket:
  Burst-friendly. APIs have natural burst patterns.
  A business user sending 500 requests in 1 second then idle for 59s
  should NOT be rate limited (if under 10K/min total).
```

---

## ğŸ— Quota Architecture

```mermaid
graph TB
    REQ["Request<br/>API Key: sk_abc"] --> AUTH["Auth Service<br/>â†’ Tenant: t_abc<br/>â†’ Plan: pro"]

    AUTH --> RL["Rate Limiter"]

    RL --> CHECK1{"Tenant quota<br/>1K/min?"}
    CHECK1 -->|"Under"| CHECK2{"Per-user limit<br/>100/min?"}
    CHECK1 -->|"Over"| REJECT["429 â€” Tenant quota exceeded"]

    CHECK2 -->|"Under"| CHECK3{"Per-endpoint<br/>/search: 10/min?"}
    CHECK2 -->|"Over"| REJECT2["429 â€” User rate limited"]

    CHECK3 -->|"Under"| ALLOW["âœ… ALLOW"]
    CHECK3 -->|"Over"| REJECT3["429 â€” Endpoint rate limited"]

    style REJECT fill:#f44336,color:#fff
    style REJECT2 fill:#f44336,color:#fff
    style REJECT3 fill:#f44336,color:#fff
    style ALLOW fill:#4caf50,color:#fff
```

### Evaluation Order

```
Rate limits are checked in order of specificity:

  1. Global platform limit    (500K req/sec)     â€” protect infrastructure
  2. Per-IP limit             (50 req/min)        â€” block anonymous abuse
  3. Per-tenant limit         (plan-based)        â€” enforce quota
  4. Per-user limit           (100 req/min)       â€” per-user fairness
  5. Per-endpoint limit       (varies)            â€” protect expensive ops

  First limit hit â†’ reject with specific error message.
  
  Short-circuit: if #1 or #2 rejects, don't even check #3-5.
  Saves Redis ops for clearly abusive requests.
```

---

## ğŸ’¡ Burst Allowance

### Token Bucket Configuration Per Plan

| Plan | Sustained Rate | Bucket Size | Burst Duration | Max Burst Rate |
|------|---------------|-------------|---------------|---------------|
| Free | 1.67/sec (100/min) | 100 tokens | N/A (fixed window) | N/A |
| Pro | 16.7/sec (1K/min) | 25 tokens | 1.5s | 25 req instantly |
| Business | 167/sec (10K/min) | 500 tokens | 3s | 500 req instantly |
| Enterprise | 1,667/sec (100K/min) | 5,000 tokens | 3s | 5,000 req instantly |

```
Business plan example (10K/min = 167/sec):

  Scenario: API client batch-processes 500 records
  Sends 500 requests in 2 seconds

  Without burst: 500 req / 2 sec = 250/sec > 167/sec â†’ REJECTED after 334 reqs
  With burst:    bucket has 500 tokens â†’ all 500 pass instantly âœ…
                 Then: refills at 167/sec (sustained rate)
                 After 3 seconds: bucket has ~500 tokens again

  Customer experience: batch jobs "just work" without complicated retry logic.
```

---

## ğŸ“Š Endpoint Cost Weighting

### The Problem

```
Not all requests are equal:

  GET /users/{id}          â†’ 1ms, hits cache
  GET /search?q=complex    â†’ 200ms, full-text search, heavy CPU
  POST /export/csv         â†’ 5 seconds, scans entire dataset

Flat rate limiting (1000 req/min) means:
  1000 search requests = 200 seconds of CPU time
  1000 user gets = 1 second of CPU time

  Same "cost" to rate limiter, 200Ã— different cost to infrastructure.
```

### Solution: Weighted Quotas

```
Each endpoint has a "cost" in tokens:

  GET  /users/{id}:        1 token
  GET  /users:             2 tokens (list operation)
  GET  /search:            5 tokens (expensive)
  POST /export:           50 tokens (very expensive)
  GET  /analytics:        10 tokens (aggregation)

Pro plan: 1,000 tokens/min (not "requests" â€” tokens)

  1,000 user gets (1 Ã— 1,000 = 1,000 tokens)  â† uses full quota
  200 searches (5 Ã— 200 = 1,000 tokens)        â† uses full quota
  20 exports (50 Ã— 20 = 1,000 tokens)          â† uses full quota

Implementation:
  Token bucket with variable deduction:
  requested_tokens = endpoint_cost[request.path]
  if tokens >= requested_tokens â†’ allow, deduct
  else â†’ reject
```

---

## ğŸ”„ Dynamic Quota Updates

### Real-Time Plan Changes

```
When a tenant upgrades from Pro â†’ Business:

  1. Admin API: UPDATE plans SET tier = 'business' WHERE tenant_id = 't_abc'
  2. PostgreSQL trigger â†’ publish event
  3. Redis Pub/Sub: PUBLISH 'config_update' '{"tenant":"t_abc","plan":"business"}'
  4. All API servers: receive â†’ update local rule cache
  
  Time to take effect: < 2 seconds
  
  The current window counter stays (doesn't reset).
  New limit applies immediately.
  If old count < new limit â†’ instantly unblocked.
```

### Temporary Quota Boost

```
Use case: tenant has a planned marketing campaign, needs 5Ã— quota for 2 hours.

  POST /v1/rate-limits/overrides
  {
    "tenant_id": "t_abc",
    "multiplier": 5,
    "starts_at": "2026-02-23T14:00:00Z",
    "ends_at": "2026-02-23T16:00:00Z",
    "reason": "Product launch campaign"
  }

  Rate limiter:
    normal_limit = plan.limit  (1,000/min)
    if active_override: effective_limit = 1,000 Ã— 5 = 5,000/min

  Override auto-expires. No manual cleanup needed.
```

---

## ğŸ“Š Quota Usage Dashboard

### Per-Tenant View

```
Tenant: Acme Corp (Business Plan)
Period: Last 24 hours

  Quota Usage:
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 78% of daily limit
  
  Requests today: 780,000 / 1,000,000

  By Endpoint:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Endpoint           â”‚ Requests â”‚ % Total â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ GET /users/{id}    â”‚ 450,000  â”‚ 57.7%   â”‚
  â”‚ GET /users         â”‚ 180,000  â”‚ 23.1%   â”‚
  â”‚ POST /users        â”‚ 100,000  â”‚ 12.8%   â”‚
  â”‚ GET /search        â”‚ 40,000   â”‚ 5.1%    â”‚
  â”‚ POST /export       â”‚ 10,000   â”‚ 1.3%    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Rate Limit Hits (429s): 342 (0.04%)
  Peak QPS: 450 req/sec (at 14:23 UTC)
  Avg Latency Impact: +0.3ms per request
```

### Quota Alerts

```
Alert rules:
  â€¢ Tenant at 80% of daily quota â†’ email tenant (info)
  â€¢ Tenant at 95% of daily quota â†’ email tenant (warning)
  â€¢ Tenant hitting 429s > 1% of requests â†’ email tenant + internal alert
  â€¢ Tenant consistently at 100% for 3+ days â†’ sales notification (upsell)
```

---

## â¬…ï¸ [â† Distributed Challenges](05-distributed-challenges.md) Â· [Failure & Recovery â†’](07-failure-recovery.md)
